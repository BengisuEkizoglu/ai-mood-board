# Ollama Configuration (Optional - for local AI text analysis)
# Install Ollama from https://ollama.ai and run: ollama pull qwen2.5:7b
# OLLAMA_HOST=http://localhost:11434 (default)

# Server Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=True

# CORS Configuration
ALLOWED_ORIGINS=http://localhost:3000,http://127.0.0.1:3000 